-------------------------Setting up project structure---------------------------

1. Create repo, clone it in local
2. Install dependencies, Create & Activate the virtual environment

   winget source update
   winget install --id Python.Python.3.11 --source winget
   py -3.11 --version
   py -3.11 -m venv capstone
   .\capstone\Scripts\activate
   pip install mlflow==2.14.3
   mlflow --version (Use MLflow version 2.15.0. to log model in Dagshub) 

3. pip install cookiecutter
4. cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science
5. Rename src.models -> src.model
6. git add - commit - push

-------------------------Setup MLFlow on Dagshub---------------------------
7. Go to: https://dagshub.com/dashboard
8. Create > New Repo > Connect a repo > (Github) Connect > Select your repo > Connect
9. Copy experiment tracking url and code snippet. (Also try: Go To MLFlow UI)
10. pip install dagshub & mlflow=2.15.0

11. Run the exp notebooks
12. git add - commit - push

13. dvc init
14. create a local folder as "local_s3" (temporary work)
15. on terminal - "dvc remote add -d mylocal local_s3"

16. Add code to below files/folders inside src dir:
    - logger
    - data_ingestion.py
    - data_preprocessing.py
    - feature_engineering.py
    - model_building.py
    - model_evaluation.py
    - register_model.py
17. add file - dvc.yaml (till model evaluation.metrics)
18. add file - params.yaml
29. DVC pipeline is ready to run - dvc repro
20. Once do - dvc status
21. git add - commit - push

22. Need to add S3 as remote storage - Create IAM User(keep cred) and S3 bucket
23. pip install - dvc[s3] & awscli
24. Checking/deleting dvc remote (optional) - [dvc remote list & dvc remote remove <name>] 
25. Set aws cred - aws configure
26. Add s3 as dvc remote storage - dvc remote add -d myremote s3://<bucket-name>

27. Create new dir - flask_app | Inside that, add rest of the files and dir
28. pip install flask and run the app (dvc push - to push data to S3)

29. pip freeze > requirements.txt
30. Add .github/workflows/ci.yaml file

31. Create key token on Dagshub for auth: Go to dagshub repo > Your settings > Tokens > Generate new token
    >> Please make sure to save token << >> Capstone proj: fa7d5d9652cebe2aa3742805f8295f4ac26e2e21<<
    >> Add this auth token to github secret&var and update on ci file

32. Add dir "tests"&"scripts" and files within. This will contain our test related scripts for CI.